{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c74dd6-a89c-4f21-af26-279e2e175c6a",
   "metadata": {},
   "source": [
    "### Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb4ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "To find the probability that an employee is a smoker given that they use the health insurance plan, we can use conditional probability.\n",
    "\n",
    "Let:\n",
    "\n",
    "A be the event that an employee uses the health insurance plan.\n",
    "S be the event that an employee is a smoker.\n",
    "\n",
    "We are given:\n",
    "\n",
    "    P(A) = Probability that an employee uses the health insurance plan = 70% = 0.70.\n",
    "    P(S | A) = Probability that an employee is a smoker given that they use the health insurance plan.\n",
    "\n",
    "We are also given that 40% of the employees who use the plan are smokers. So:\n",
    "\n",
    "    P(S | A) = Probability that an employee is a smoker given that they use the health insurance plan = 40% = 0.40.\n",
    "\n",
    "Now, we can use the conditional probability formula:\n",
    "\n",
    "    P(S∣A)= P(S∩A)/P(A)\n",
    "\n",
    "    Where:\n",
    "    P(S | A) is the conditional probability of being a smoker given that they use the health insurance plan.\n",
    "    P(S ∩ A) is the joint probability of being a smoker and using the health insurance plan.\n",
    "    P(A) is the probability of using the health insurance plan.\n",
    "    \n",
    "We already have P(A) and P(S | A), so we can calculate P(S ∩ A):\n",
    "\n",
    "    P(S∩A)=P(S∣A)∗P(A)=0.40∗0.70=0.28\n",
    "\n",
    "So, the probability that an employee is a smoker given that they use the health insurance plan is 0.28 or 28%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb52da3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f351d4f6-fd26-4357-b9ab-a647c3d563ac",
   "metadata": {},
   "source": [
    "### Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d011d1",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes and Multinomial Naive Bayes are two variants of the Naive Bayes classifier, each designed for different types of\n",
    "data and assumptions. Here are the key differences between them:\n",
    "\n",
    "#### Data Type:\n",
    "\n",
    "* Bernoulli Naive Bayes: \n",
    "  It is used for binary or binarized data, where each feature is either present (1) or absent (0). It's commonly applied to text   classification tasks where the presence or absence of words in documents is considered.\n",
    " \n",
    " \n",
    "* Multinomial Naive Bayes: \n",
    "  It is used for discrete data, typically representing counts or frequencies of categorical features. It's widely used in text \n",
    "  classification, where the features often represent word counts or TF-IDF values.\n",
    "\n",
    "#### Feature Representation:\n",
    "\n",
    "* Bernoulli Naive Bayes: \n",
    "  Assumes binary features, making it suitable for cases where you want to model whether a feature is present or not (e.g., word   presence in a document).\n",
    "  \n",
    "  \n",
    "* Multinomial Naive Bayes: \n",
    "  Deals with discrete feature counts or frequencies, which is appropriate for cases where you want to capture the number of     \n",
    "  occurrences of different categories (e.g., word counts in a document).\n",
    "\n",
    "#### Feature Independence Assumption:\n",
    "\n",
    "* Both Bernoulli and Multinomial Naive Bayes make the same strong independence assumption known as the \"naive\" assumption. They   assume that all features are conditionally independent given the class label, which simplifies the calculation of     \n",
    "  probabilities.\n",
    "\n",
    "#### Use Cases:\n",
    "\n",
    "* Bernoulli Naive Bayes: \n",
    "  Useful for text classification tasks, spam detection, sentiment analysis, and situations where you want to model the presence   or absence of features.\n",
    "        \n",
    "        \n",
    "* Multinomial Naive Bayes:\n",
    "  Well-suited for text classification tasks, document categorization, and problems involving discrete   \n",
    "  feature counts, such as bag-of-words representations.\n",
    "\n",
    "#### Probability Estimation:\n",
    "\n",
    "* Bernoulli Naive Bayes: \n",
    "  Estimates probabilities based on the presence or absence of features. It models feature occurrences as binary events.\n",
    "\n",
    "* Multinomial Naive Bayes: \n",
    "  Estimates probabilities based on the frequency or counts of features. It models feature occurrences as discrete events.\n",
    "\n",
    "\n",
    "\n",
    "##### Example:\n",
    "\n",
    "For a Bernoulli Naive Bayes classifier, you might represent a document as a binary vector, indicating whether each word is present (1) or absent (0).For a Multinomial Naive Bayes classifier, you might represent a document as a vector of word counts, where each entry represents the count of a specific word.\n",
    "\n",
    "In summary, the choice between Bernoulli Naive Bayes and Multinomial Naive Bayes depends on the nature of your data and the way you've encoded your features. If your features are binary (presence/absence), Bernoulli Naive Bayes is suitable. If your features are discrete counts or frequencies, Multinomial Naive Bayes is more appropriate, particularly in text classification scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a08510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74599ac6-59f2-4fee-96ab-99971bc3c972",
   "metadata": {},
   "source": [
    "## Q3. How does Bernoulli Naive Bayes handle missing values?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b3e67b",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes, like other Naive Bayes variants, can handle missing values in a straightforward manner. When dealing with missing values, you typically have a few options:\n",
    "\n",
    "* #### Ignoring Missing Values:\n",
    "One approach is to simply ignore instances (rows) that contain missing values. This can be a reasonable choice if missing values are rare and not systematically related to the class labels. In this case, you would exclude instances with missing values from both training and testing datasets.\n",
    "\n",
    "* #### Imputing Missing Values: \n",
    "Another option is to impute (fill in) the missing values with some suitable values. For Bernoulli Naive Bayes, which deals with binary features (0 or 1), you might impute missing values with the most frequent value (0 or 1) in the corresponding feature across the dataset or class. This imputation method should be chosen based on the nature of your data.\n",
    "\n",
    "   \n",
    " \n",
    "Treating Missing Values as a Separate Category: In some cases, missing values themselves may carry information. You can treat missing values as a distinct category (e.g., \"unknown\" or \"-1\") in your binary features. This approach allows the classifier to learn from instances with missing values, provided that missingness is informative.\n",
    "\n",
    "It's essential to make a choice based on the specifics of your dataset and the problem you're trying to solve. Handling missing values appropriately can help prevent biased or inaccurate model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef094656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a0b20d6-a569-4fb4-ab06-896b4bf2f032",
   "metadata": {},
   "source": [
    "## Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a349775",
   "metadata": {},
   "source": [
    "Yes, Gaussian Naive Bayes can be used for multi-class classification tasks. Gaussian Naive Bayes is a variant of the Naive Bayes classifier \n",
    "that assumes continuous data and models the distribution of each feature using a Gaussian (normal) distribution. \n",
    "While it's often used for binary or two-class classification, it can be extended to handle multi-class classification as well.\n",
    "\n",
    "To use Gaussian Naive Bayes for multi-class classification, you typically follow one of two common approaches:\n",
    "\n",
    "* #### One-vs-Rest (OvR) or One-vs-All (OvA): \n",
    "In this approach, you create a separate binary classifier for each class. For example, if you have N classes, you train N binary \n",
    "classifiers, where each classifier distinguishes one class from the rest (hence the name \"One-vs-Rest\" or \"One-vs-All\"). During prediction, you obtain the class with the highest probability from all the classifiers.\n",
    "\n",
    "* #### Multinomial Naive Bayes: \n",
    "Alternatively, you can use a variation of Naive Bayes called \"Multinomial Naive Bayes\" for multi-class problems, especially when dealing with discrete or count-based data (e.g., text classification). Multinomial Naive Bayes extends the Naive Bayes model to handle multiple classes directly. It estimates probabilities using a multinomial distribution.\n",
    "\n",
    "    \n",
    "The choice between Gaussian Naive Bayes with OvR and Multinomial Naive Bayes depends on the nature of your data and the specific requirements \n",
    "of your classification task:\n",
    "\n",
    "Use Gaussian Naive Bayes with OvR when dealing with continuous data that can be modeled well by Gaussian distributions, and when you prefer \n",
    "simplicity in handling multi-class problems.\n",
    "Use Multinomial Naive Bayes when dealing with discrete data, such as text data represented by word counts or TF-IDF values, for multi-class \n",
    "text classification tasks.\n",
    "Both approaches are valid and widely used, but the choice should align with the characteristics of your data and the assumptions of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955050f-6244-4614-b71a-85f221b651ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Q5. Assignment:\n",
    "\n",
    "* Data preparation:\n",
    "  Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Spambase). This dataset \n",
    "  contains email messages, where the goal is to predict whether a message is spam or not based on several input features.\n",
    "\n",
    "* Implementation:\n",
    "  Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the scikit-learn library in Python. \n",
    "  Use 10-fold cross-validation to evaluate the performance of each classifier on the dataset. You should use the default hyperparameters for each \n",
    "  classifier.\n",
    "\n",
    "* Results:\n",
    "  Report the following performance metrics for each classifier:\n",
    "  Accuracy\n",
    "  Precision\n",
    "  Recall\n",
    "  F1 score\n",
    "  \n",
    "* Discussion:\n",
    "  Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is the case? Are there any limitations \n",
    "  of Naive Bayes that you observed?\n",
    "\n",
    "* Conclusion:\n",
    "  Summarise your findings and provide some suggestions for future work.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b3fb20",
   "metadata": {},
   "source": [
    "DATASET LINK: https://archive.ics.uci.edu/datasets?search=Spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb211a4-0664-4467-9254-fc1351785afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB,MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46729fec-3ae9-4aa2-8aba-9ac14d74b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = pd.read_csv('spambase.data',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf537610-69c5-4d0b-bf38-b2159efc33d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...  0.41  \\\n",
       "0  0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "1  0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "2  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "3  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.00   \n",
       "\n",
       "    0.42  0.43  0.778   0.44   0.45  3.756   61   278  1  \n",
       "0  0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "1  0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "2  0.137   0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
       "3  0.135   0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
       "4  0.223   0.0  0.000  0.000  0.000  3.000   15    54  1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff6be85-1035-4c17-b70c-7000516b77c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4600, 58)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd0e7499-83ac-4840-b96d-917685647e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=spam_data.iloc[:,:-1]\n",
    "y=spam_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "481a23e2-4759-4a2b-95ea-4fce4eeee209",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c008842e-5eb8-45f3-966f-e3d4235b300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8939130434782608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92       699\n",
      "           1       0.90      0.82      0.86       451\n",
      "\n",
      "    accuracy                           0.89      1150\n",
      "   macro avg       0.90      0.88      0.89      1150\n",
      "weighted avg       0.89      0.89      0.89      1150\n",
      "\n",
      "[[659  40]\n",
      " [ 82 369]]\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes\n",
    "ber=BernoulliNB()\n",
    "ber.fit(X_train,y_train)\n",
    "y_pred=ber.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52630a33-4781-4de3-952c-9d02707a7ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788695652173913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83       699\n",
      "           1       0.73      0.73      0.73       451\n",
      "\n",
      "    accuracy                           0.79      1150\n",
      "   macro avg       0.78      0.78      0.78      1150\n",
      "weighted avg       0.79      0.79      0.79      1150\n",
      "\n",
      "[[579 120]\n",
      " [123 328]]\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "mul=MultinomialNB()\n",
    "mul.fit(X_train,y_train)\n",
    "y_pred=mul.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f8b2093-9623-407d-9201-857559f5122d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788695652173913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83       699\n",
      "           1       0.73      0.73      0.73       451\n",
      "\n",
      "    accuracy                           0.79      1150\n",
      "   macro avg       0.78      0.78      0.78      1150\n",
      "weighted avg       0.79      0.79      0.79      1150\n",
      "\n",
      "[[579 120]\n",
      " [123 328]]\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes \n",
    "gau=MultinomialNB()\n",
    "gau.fit(X_train,y_train)\n",
    "y_pred=gau.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1c3f8-6e0b-491d-b10b-8dfa1e813bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussion\n",
    "From above we can say that Bernoulli Naive Bayes has provided best result. \n",
    "As Bernoulli has only two value as classification either 0 or 1, this model perform well for spambase data \n",
    "Comapare to other model Bernoulli has higher accuracy and less number for FP and FT as well.\n",
    "\n",
    "# Conclusion:\n",
    "For email spam data set FP is more importan as we do not want to tag wrong mail as spam so considering this as requirement Bernoulli Bayes has \n",
    "provided more accurate result compare to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf0ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
